import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random
import requests
import nltk
import re
from collections import Counter
from wordcloud import WordCloud
from nltk.corpus import stopwords
import io
from  utils.text_processing import clean_text, get_ngrams, get_text_stats, find_pattern, download_nltk_resources

# Configuraci칩n inicial de la p치gina
st.set_page_config(
    page_title="An치lisis de Sentimientos en Rese침as de Steam",
    page_icon="游꿡",
    layout="wide"
)

# T칤tulo principal
st.title("An치lisis de Sentimientos en Rese침as de Steam")
st.markdown("Este es un proyecto para practicar el procesamiento de lenguaje natural con rese침as de videojuegos de la API de Steam.")

# Asegurar que los recursos de NLTK est칠n descargados
download_nltk_resources()

# Secci칩n de configuraci칩n
st.header("Configuraci칩n")

col1, col2, col3 = st.columns(3)
with col1:
    id_game = st.text_input("ID del juego", "2246340", help="Por ejemplo: Monster Hunter Wilds = 2246340")
with col2:
    language = st.selectbox("Idioma de las rese침as", ["spanish", "english", "french", "german"], index=0)
with col3:
    num_per_page = st.slider("N칰mero de rese침as", min_value=10, max_value=100, value=100, step=1)

#==============================================================================================================
#==================================== Seccion 1: Obtener Rese침as ==============================================
#==============================================================================================================

# Bot칩n para obtener las rese침as
if st.button("Obtener Rese침as"):
    with st.spinner("Descargando rese침as de Steam..."):
        # URL de la API de Steam para obtener rese침as
        url = f"https://store.steampowered.com/appreviews/{id_game}?json=1&language={language}&num_per_page={num_per_page}"

        try:
            # Realizar la solicitud a la API
            response = requests.get(url)
            data = response.json()

            # Extraer las rese침as del JSON
            reviews = data.get('reviews', [])

            if not reviews:
                st.error("No se encontraron rese침as para este juego con los par치metros especificados.")
                st.stop()

            # Crear un DataFrame a partir de las rese침as
            df_reviews = pd.DataFrame(reviews)

            # Guardar el DataFrame en la sesi칩n
            st.session_state.df_reviews = df_reviews
            st.session_state.game_id = id_game

            st.success(f"Se han descargado {len(reviews)} rese침as correctamente!")
        except Exception as e:
            st.error(f"Error al obtener las rese침as: {str(e)}")
            st.stop()

# Verificar si el DataFrame esta en la sesion
if 'df_reviews' not in st.session_state:
    st.info("Por favor, obten las rese침as primero usando el boton de arriba.")
    st.stop()

df_reviews = st.session_state.df_reviews

# Mostrar informacion basica del dataframe
st.header("Informacion del Dataset")
st.write(f"Numero de rese침as: {len(df_reviews)}")

# Mostrar las primeras filas del Dataframe
with st.expander("Ver primeras filas del DataFrame"):
    st.write("Columnas principales del Dataframe:")
    if 'review' in df_reviews.columns:
        simple_df = df_reviews[['review', 'voted_up', 'author', 'timestamp_created']]
        st.dataframe(simple_df.head())
    else:
        st.warning("El DataFrame no contiene la columna 'review' esperada.")

#==============================================================================================================
#==================================== Seccion 2: Analisis de sentimiento ======================================
#==============================================================================================================
# Seccion de analisis de sentimiento
st.header("Analisis de sentimiento")

# Creando columna de  'sentiment' basandonos de la columna de 'voted_up'
if 'voted_up' in df_reviews.columns:
    df_reviews['sentiment'] = df_reviews['voted_up'].apply(lambda x: 'Positive' if x else 'Negative')

    # contar la cantidad de rese침as por sentimiento
    sentiment_counts = df_reviews['sentiment'].value_counts()

    #Graficar el resultado (pastel)
    fig, ax = plt.subplots(figsize = (3, 3))
    ax.pie(sentiment_counts, labels= sentiment_counts.index, autopct='%1.1f', startangle=90)
    ax.axis('equal')
    ax.set_title(f'Porcentaje de rese침as del juego {st.session_state.game_id} en steam')
    st.pyplot(fig)

    #Mostrar conteo exacto
    st.write('Conteo de Sentimientos:')
    st.write(pd.DataFrame(sentiment_counts).transpose())
else:
    st.warning("No se encontro la columna 'voted_up' en los datos.")

#==============================================================================================================
#==================================== Seccion 3: Rese침as Largas / Cortas ======================================
#==============================================================================================================

# Seccion de rese침as largas y cortas
st.header("Rese침as largas y cortas")

if 'review' in df_reviews.columns and len(df_reviews) > 0:
    #Calcular longitud de cada rese침a
    df_reviews['review_length'] = df_reviews['review'].apply(len)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader('Rese침a mas larga')
        longest_review = df_reviews.loc[df_reviews['review_length'].idxmax()]['review']
        st.text_area("", longest_review, height=200, disabled=True)

    with col2:
        st.subheader('Rese침a mas corta')
        min_length_review = df_reviews.loc[df_reviews['review_length'].idxmin()]['review']
        st.text_area("", min_length_review, height=200, disabled=True)

    # Rese침a aleatoria
    st.subheader('Rese침a aleatoria')
    if st.button("Selecciona Rese침a Aleatria"):
        random_index = random.randint(0, len(df_reviews) - 1)
        st.session_state.random_review = df_reviews['review'][random_index]
        st.session_state.random_index = random_index

    if 'random_review' not in st.session_state:
        random_index = random.randint(0, len(df_reviews)-1)
        st.session_state.random_review = df_reviews['review'][random_index]
        st.session_state.random_index = random_index

    st.text_area("Rese침a original", st.session_state.random_review, height=150, disabled=True)

#==================================== Uso de Stopwords ======================================
    # Tokenizar y limpiar la rese침a
    clean_words = clean_text(st.session_state.random_review, language=language)
    clean_review = " ".join(clean_words)

    st.text_area("Rese침a limpia (ya aplicado stopwords)", clean_review, height=150, disabled=True)

#==============================================================================================================
#==================================== Seccion 4: Estadisticas de texto ========================================
#==============================================================================================================

#Estadisticas de texto
st.header("Numero de palabras")

if 'review' in df_reviews.columns:
    #juntar todas las rese침as en un solo texto
    all_reviews = " ".join(df_reviews['review'].tolist())

    #Obtener estadisticas de texto
    text_stats = get_text_stats(all_reviews, language=language)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total de palabras", text_stats['word_count'])
    with col2:
        st.metric("Palabras unicas", text_stats['unique_count'])
    with col3:
        st.metric("Promedio de palabras por rese침as", round(text_stats['word_count'] / len(df_reviews), 2))

#==============================================================================================================
#==================================== Seccion 5: Palabras comunes =============================================
#==============================================================================================================

#Palabras comunes
st.header("Palabras Comunes")

if 'review' in df_reviews.columns:
    # Usar estadisticas previamente calculadas
    word_freq = Counter(text_stats['clean_tokens'])
    most_common_words = word_freq.most_common(10)
    words, counts = zip(*most_common_words)

    #graficar las palabras mas frecuentes
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.barplot(x=list(words), y=list(counts), ax=ax)
    ax.set_title("Palabras mas repetidas en las rese침as")
    ax.set_xlabel("Palabra")
    ax.set_ylabel("Frecuencia")
    plt.xticks(rotation=45)
    st.pyplot(fig)

#==============================================================================================================
#==================================== Seccion 6: Palabras Unicas ==============================================
#==============================================================================================================
# Secci칩n de palabras 칰nicas
st.header("Palabras 칔nicas")

if 'review' in df_reviews.columns:
    # Obtener palabras que aparecen solo una vez
    rare_words = [word for word, count in word_freq.items() if count == 1]

    if len(rare_words) > 20:
        sample_rare = random.sample(rare_words, 20)
        st.write(f"Mostrando de 20 palabras 칰nicas (de un total de {len(rare_words)}):")
        st.write(", ".join(sample_rare))
    else:
        st.write(f"Palabras que aparecen solo una vez ({len(rare_words)}):")
        st.write(", ".join(rare_words))

#==============================================================================================================
#==================================== Seccion 7: WordCloud ====================================================
#==============================================================================================================

# Secci칩n de WordCloud
st.header("WordCloud")

if 'review' in df_reviews.columns:
    st.write("Nube de palabras de las rese침as (ya aplicado con stopwords):")

    # Crear un texto combinado de todas las palabras limpias
    clean_text_combined = " ".join(text_stats['clean_tokens'])

    # Generar WordCloud
    wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100, contour_width=3, contour_color='steelblue')
    wordcloud.generate(clean_text_combined)

    # Convertir la imagen a bytes para mostrarla
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

#==============================================================================================================
#==================================== Seccion 8: Distribucion de vocabulario ==================================
#==============================================================================================================

# Secci칩n de distribuci칩n de vocabulario
st.header("Distribuci칩n de Vocabulario")

if 'review' in df_reviews.columns:
    # Contar cu치ntas veces aparece cada palabra
    word_counts = Counter(text_stats['clean_tokens'])

    # Contar cu치ntas palabras aparecen 1 vez, 2 veces, etc.
    frequency_distribution = Counter([count for word, count in word_counts.items()])

    # Ordenar por frecuencia para el gr치fico
    sorted_freq = sorted(frequency_distribution.items())
    x, y = zip(*sorted_freq[:20])  # Mostrar solo las primeras 20 frecuencias

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.bar(x, y)
    ax.set_xlabel("Frecuencia de aparici칩n")
    ax.set_ylabel("N칰mero de palabras")
    ax.set_title("Distribuci칩n de frecuencia de palabras")

    st.pyplot(fig)

    # Tabla con detalles
    st.write("Interpretaci칩n: El eje X muestra cu치ntas veces aparece una palabra, y el eje Y muestra cu치ntas palabras distintas aparecen ese n칰mero de veces.")

    dist_df = pd.DataFrame({
        'Frecuencia de aparici칩n': x,
        'N칰mero de palabras': y
    })
    st.dataframe(dist_df)


#==============================================================================================================
#==================================== Seccion 9: N-gramas =====================================================
#==============================================================================================================
# Secci칩n de n-gramas
st.header("N-gramas")

if 'random_review' in st.session_state:
    clean_review = " ".join(clean_text(st.session_state.random_review, language=language))

    tab1, tab2, tab3, tab4 = st.tabs(["Bi-gramas", "Tri-gramas", "Cuatri-gramas", "Quintu-gramas"])

    with tab1:
        bigrams = get_ngrams(clean_review, n=2, language=language)
        st.write(f"Bi-gramas de la rese침a aleatoria ({len(bigrams)} en total):")
        if bigrams:
            st.write(str(bigrams[:20]) + ("..." if len(bigrams) > 20 else ""))
        else:
            st.write("No se encontraron bi-gramas en esta rese침a.")

    with tab2:
        trigrams = get_ngrams(clean_review, n=3, language=language)
        st.write(f"Tri-gramas de la rese침a aleatoria ({len(trigrams)} en total):")
        if trigrams:
            st.write(str(trigrams[:20]) + ("..." if len(trigrams) > 20 else ""))
        else:
            st.write("No se encontraron tri-gramas en esta rese침a.")

    with tab3:
        cuatrigrams = get_ngrams(clean_review, n=4, language=language)
        st.write(f"Cuatri-gramas de la rese침a aleatoria ({len(cuatrigrams)} en total):")
        if cuatrigrams:
            st.write(str(cuatrigrams[:20]) + ("..." if len(cuatrigrams) > 20 else ""))
        else:
            st.write("No se encontraron cuatri-gramas en esta rese침a.")

    with tab4:
        quitugrams = get_ngrams(clean_review, n=5, language=language)
        st.write(f"Quintu-gramas de la rese침a aleatoria ({len(quitugrams)} en total):")
        if quitugrams:
            st.write(str(quitugrams[:20]) + ("..." if len(quitugrams) > 20 else ""))
        else:
            st.write("No se encontraron quintu-gramas en esta rese침a.")

#==============================================================================================================
#==================================== Seccion 10: Expresiones regulares =======================================
#==============================================================================================================
# Secci칩n de eliminaci칩n de stopwords
st.header("Eliminaci칩n de Stopwords")

if 'random_review' in st.session_state:
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Rese침a Original")
        st.write(st.session_state.random_review)

        # Tokenizar para mostrar estad칤sticas
        tokens_original = nltk.word_tokenize(st.session_state.random_review.lower(), language=language)
        st.write(f"N칰mero de palabras: {len(tokens_original)}")

    with col2:
        st.subheader("Rese침a sin Stopwords")
        clean_words = clean_text(st.session_state.random_review, language=language)
        clean_review = " ".join(clean_words)
        st.write(clean_review)
        st.write(f"N칰mero de palabras: {len(clean_words)}")

    # Mostrar las stopwords que se eliminaron
    original_set = set(tokens_original)
    clean_set = set(clean_words)
    removed_words = original_set - clean_set

    stop_words = set(stopwords.words(language))
    common_stops = removed_words.intersection(stop_words)

    st.subheader("Stopwords eliminadas")
    st.write(f"Se eliminaron {len(removed_words)} palabras, de las cuales {len(common_stops)} son stopwords comunes.")

    if common_stops:
        st.write(", ".join(list(common_stops)[:30]) + ("..." if len(common_stops) > 30 else ""))

# Secci칩n final con los requisitos del proyecto
st.header("Creado por:")
st.markdown(""" 737066 | Victor M. Telles A. | (AHTyler)""")

# Agregar footer
st.markdown("---")
st.write("Desarrollado con Streamlit para el an치lisis de sentimientos en rese침as de Steam")